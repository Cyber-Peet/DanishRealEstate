Machine learning is a fast developing field of science. Everyday new frameworks and projects become available to the public through open source libraries, like the ones used in this study (\textit{Tensorflow and Keras}). The reason for the fast developing field is that the world we are living in today is a data driven world, and all big companies harvest data like never before. But for small companies it might not be possible to harvest the same amount of data due to lack of resources. This study has investigated different ideas of how small companies like the real estate agencies in Denmark might be able to grow through open sourced libraries and limited datasets.
\vspace{3mm}\\
In this study it has been established that by transfer learned training it was possible to use a general-domain CNN as an accurate feature extractor, for which real estate agencies can increase customer engagement. The pretrained models were able to learn meaningful representations of rooms, through training with limited datasets. It was proven that the general-domain model could be trained to obtain an in-domain like top-1 accuracy for the \hyperref[sec:DRE19]{DRE19} dataset. Through investigation of the images it was experienced that the models could be trained to learn meaningful feature vectors of the rooms, which directly could be translated as the model being able to learn visual aesthetics of rooms.
\vspace{3mm}\\
A previous study \textbf{\textit{Ingwersen}}\autocite{Ingwersen} claims that the preprocessing scheme had an important factor in producing meaningful representations. In this study however that claim were refuted. The preprocessing scheme should be chosen according to how the models were pre-trained.
\vspace{3mm}\\
Investigation of the contrastive learning have been done and also tried implemented, the early stages of the training seemed to work well, but the model broke halfway through, and no results were acquired. The author of this paper believes that it would have proven to be a success if the training were completed. The author also believes that the model failed to complete training due to the limited dataset size, and small batch sizes. The contrastive loss function might have had a batch were there were just one of any of the classes, and then were unable to minimise the loss to an other case, beacuse no other case could be found. However this should be further investigated.
\vspace{3mm}\\
In addressing the \hyperref[sec:Problem Definition]{Problem Definition} of this study, it proved to be possible to close the gap between the general-domain models and the in-domain model. The results suggest that reducing the dimensionality of the feature vector could have a saying when it comes to the top-1 accuracy used in this report. This was observed in this study, through the EffecientNetB0 model performing better than the ResNet50 model, and in previous study by \textbf{\textit{Ingwersen}}\autocite{Ingwersen}.
