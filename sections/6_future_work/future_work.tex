\subsubsection{Semi-Supervised Training on Remaining DRE19 Data} \label{sec:fwork1}
As described in \hyperref[sec:DRE19]{DRE19} only approximately a third of the full dataset has been labeled. As contrastive learning have been investigated, it would be a possible solution to use the unsupervised version of contrastive learning, as described in \textbf{textit{Chen}}\autocite{chen2020simple}, to label the remaining part of the dataset. As the real estate market never cease to exist, it is crucial for the real estate agents to implement a scaleable solution to deal with the never ending flow of new homes entering the market. The implementation of unsupervised labeling of images, together with a feature extractor similar to the one proposed in this model, will give real estate agencies an advantage over other real estate agencies on the market, by increasing customer engagement through new improved ways of searching for homes, that match the home seekers own preferences. Gaining a larger labeled dataset might also be key to achieving the larger batch sizes, that are required for the supervised version of contrastive learning described in \textbf{\textit{Khosla}}\autocite{khosla2020supervised} to be implemented.

\subsubsection{Supervised Contrastive Learning} \label{sec:fwork2}
Further studying of the supervised contrastive learning should be done in order to conquer a higher top-1 accuracy. An easy implementation, to see if the authors idea about the too small batch sizes, would be to try and run the same training, but with increased batch sizes. Maybe a batch size should be equal to the entire dataset.
